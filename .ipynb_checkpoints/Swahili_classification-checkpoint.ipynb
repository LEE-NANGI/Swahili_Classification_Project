{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SWAHILI AUDIO PREDICTION\n",
    "\n",
    "### Group 4 Members\n",
    "Nangi Mugira\n",
    "\n",
    "Collins Kanyiri\n",
    "\n",
    "Manyara Baraka\n",
    "\n",
    "Faith Nyawira\n",
    "\n",
    "Benson Kinyua\n",
    "\n",
    "Jacinta Mukii\n",
    "\n",
    "\n",
    "## 1. BUSINESS UNDERSTANDING\n",
    "\n",
    "### 1.1. Problem Statement\n",
    "Swahili, also known as Kiswahili, has a rich history that spans centuries and is now one of the most widely spoken languages in Africa, with millions of speakers across various countries. Today, Swahili is not only a language of communication but also a symbol of cultural heritage and identity for millions of people in East Africa and beyond. Its history reflects the dynamic nature of language, shaped by trade, migration, colonization, and cultural exchange over the centuries.\n",
    "\n",
    "With the increasing availability of digital audio content in Swahili, AnalytiX Insights aims to \n",
    "develop automated systems that can classify and categorize Swahili audio recordings for various applications, including speech recognition, content recommendation, and language learning tools. \n",
    "\n",
    "### 1.2 Objectives\n",
    "#### 1.2.1 Main Objective\n",
    "The objective of this data science project is to build a machine learning model capable of classifying Swahili audio recordings into predefined categories or labels. This model will enable the automated categorization of Swahili audio content, making it easier to organize, search, and retrieve relevant audio resources.\n",
    "\n",
    "#### 1.2.2 Specific Objectives\n",
    " - To develop a machine learning model capable of translating Swahili audio recordings.\n",
    " - Create a scalable and efficient system for real-time or batch audio classification.\n",
    " - To provide recommendations for further enhancements and applications.\n",
    "\n",
    "\n",
    "### 1.3 Key Challenges\n",
    "\n",
    "Data Collection: Acquiring a diverse and representative dataset of Swahili audio recordings spanning different categories and accents.\n",
    "Feature Extraction: Identifying relevant audio features or representations that capture the essence of Swahili speech.\n",
    "Model Generalization: Building a model that can generalize well across various accents, dialects, and speaking styles within Swahili.\n",
    "Real-time Processing: Designing the system for real-time or near-real-time audio classification, depending on the application.\n",
    "\n",
    "### 1.4 Scope\n",
    "\n",
    "This project will focus on the development of a machine learning model for Swahili audio classification. It will involve data collection, preprocessing, feature extraction, model training, and evaluation. The model will be designed to classify audio recordings into respective English words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import noisereduce as nr\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "\n",
    "# Unzip audio zip file\n",
    "# shutil.unpack_archive('Data/Swahili_words.zip', 'Swahili_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview train set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview test set\n",
    "display(test.head(), train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "train.Swahili_word.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some words\n",
    "for word in random.sample(train.Swahili_word.unique().tolist(), 6):\n",
    "  sample = train[train.Swahili_word == word].Word_id.sample(1).values[0]\n",
    "  display(word, sample, ipd.Audio('Swahili_words/'+ sample ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DATA CLEANING\n",
    "\n",
    "1. **Load Audio Files:** It can load multiple audio files from a specified folder, allowing you to work with a collection of audio recordings.\n",
    "\n",
    "2. **Visualize Audio Waveforms:** It visualizes the waveform of each loaded audio file using Matplotlib, which helps you inspect the raw audio data.\n",
    "\n",
    "3. **Resample Audio:** It resamples the audio to a specified target sampling rate if the native sampling rate of the audio files differs from the target rate. This can be important when you need audio data to be at a consistent sampling rate.\n",
    "\n",
    "4. **Optional Noise Reduction:** Although this code includes a placeholder for noise reduction using the `noisereduce` library, you can replace it with your own noise reduction techniques if needed. Noise reduction is particularly useful when dealing with audio recordings that contain background noise.\n",
    "\n",
    "5. **Normalization:** It normalizes the audio data to ensure that it falls within a common range, typically between -1 and 1. Normalization can help make the audio data more suitable for analysis or modeling.\n",
    "\n",
    "6. **Error Handling:** The code includes error handling to handle exceptions that may occur during audio processing, ensuring that the script doesn't crash if there are issues with specific audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dummy audio files\n",
    "data_folder = r'Swahili_words'\n",
    "audio_files = [os.path.join(data_folder, filename) for filename in os.listdir(data_folder)]  # get list of audio files\n",
    "audio_files = [audio_file for audio_file in audio_files if audio_file.endswith('.wav')]  # filter out non-audio files\n",
    "print(f'Found {len(audio_files)} files')  # print the number of files\n",
    "\n",
    "# Limit the number of visualizations to 5\n",
    "num_visualizations = 5\n",
    "for i, audio_file in enumerate(audio_files[:num_visualizations]):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file, sr=None)  # Load the audio file with its native sampling rate\n",
    "\n",
    "        # Visualize the audio waveform\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.waveshow(y, sr=sr)\n",
    "        plt.title(f\"Audio Waveform - File {i + 1}\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.show()\n",
    "\n",
    "        # Preprocessing steps\n",
    "        target_sr = 16000  # Target sampling rate (e.g., 16 kHz)\n",
    "        if sr != target_sr:\n",
    "            y = librosa.resample(y, sr, target_sr)\n",
    "            sr = target_sr\n",
    "\n",
    "        # 2. Noise reduction (optional):\n",
    "        # You can apply noise reduction techniques if the audio has background noise.\n",
    "        y= nr.reduce_noise(y, sr=sr)\n",
    "        \n",
    "    \n",
    "        # Example: y = some_noise_reduction_function(y)\n",
    "\n",
    "        # 3. Normalization:\n",
    "        # Normalize the audio to a common range, usually between -1 and 1.\n",
    "        y = librosa.util.normalize(y)\n",
    "\n",
    "        # 4. Plot the preprocessed audio waveform\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        librosa.display.waveshow(y, sr=sr)\n",
    "        plt.title(f\"Preprocessed Audio Waveform - File {i + 1}\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {audio_file}\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. EXPLORATION DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to check the audio files with the same transcription \n",
    "# Get three sample\n",
    "dict_samples=dict()\n",
    "for word in train['Swahili_word'].unique().tolist():\n",
    "    sample = train[train['Swahili_word'] == word]['Word_id'].sample(3).values[:]\n",
    "    dict_samples[word] = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show three wavefiles for all words in time domain, for easy comparison between the words\n",
    "for word in dict_samples:\n",
    "    i=0\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    fig.suptitle(word)\n",
    "    for audiofile in dict_samples[word]:\n",
    "        x, sr = librosa.load('Swahili_words/'+audiofile)\n",
    "        img = librosa.display.waveshow(x, sr=sr, ax=ax[i])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the three files of each word in frequency domain\n",
    "for word in dict_samples:\n",
    "    i=0\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    fig.suptitle(word)\n",
    "    for audiofile in dict_samples[word]:\n",
    "        x, sr = librosa.load('Swahili_words/'+audiofile)\n",
    "        X = librosa.amplitude_to_db(np.abs(librosa.stft(x)), ref=np.max)\n",
    "        img = librosa.display.specshow(X, x_axis='time', sr=sr, ax=ax[i])\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
